{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import PIL\nfrom PIL import Image\nimport librosa\nimport librosa.display\nimport numpy as np\nfrom numpy import asarray\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\nfrom pydub import AudioSegment\nimport pickle\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import preprocessing\n\nimport torch\nimport torchaudio\nimport torchvision\nfrom PIL import Image\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:37:03.169053Z","iopub.execute_input":"2022-05-21T09:37:03.169342Z","iopub.status.idle":"2022-05-21T09:37:12.240119Z","shell.execute_reply.started":"2022-05-21T09:37:03.169309Z","shell.execute_reply":"2022-05-21T09:37:12.239267Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"audio_path = 'data/genres_original/hiphop/hiphop.00005.wav'\nx , sr = librosa.load(audio_path)#x is an audio time series as a numpy array. sr is the sampling rate\nipd.Audio(audio_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataset(path, genre_list, dataset):\n    \n    num_channels = 3\n    window_sizes = [25, 50, 100]\n    hop_sizes = [10, 25, 50]\n    \n    for genre in genre_list:\n        files = librosa.util.find_files(path+genre, ext=['wav'])#this returns the entire path for each file in a genre folder\n        \n        for song in files:\n            x , sr = librosa.load(song)\n            song_id = song[71+len(genre)+1:-4]#-4 - len(genre)\n            specs_ = []\n            \n            for i in range(num_channels):\n                \n                window_length = int(round(window_sizes[i]*sr/1000))\n                hop_length = int(round(hop_sizes[i]*sr/1000))\n\n                clip = torch.Tensor(x)\n                spec = torchaudio.transforms.MelSpectrogram(sample_rate=sr, n_fft=2205, win_length=window_length, hop_length=hop_length, n_mels=128)(clip) #Check this otherwise use 2400\n                eps = 1e-6\n                spec = spec.numpy()\n                spec = np.log(spec+ eps)\n                spec = np.asarray(torchvision.transforms.Resize((128, 1500))(Image.fromarray(spec)))\n                specs_.append(spec)\n            \n            spec = np.dstack((specs_[0], specs_[1], specs_[2]))\n            dataset['song_id'].append(song_id)  \n            if song_id[-5:]!='25_30' or song_id[-5:]!='_0_50':\n                dataset[\"Mel_spectrograms\"].append(spec)  \n            dataset['label'].append(genre)\n                            \n                \n    return dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = { 'song_id':[], 'audio':[], 'Mel_spectrograms':[], 'label':[] }\npath = 'data/data_fiveSeconds/'\ngenre_list = ['jazz', 'rock', 'hiphop', 'metal', 'pop', 'disco', 'blues', 'classical', 'country', 'reggae']\ndata_diz = create_dataset(path, genre_list, dataset)  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('DATA_Mel_spectrograms.pkl', 'wb') as f:\n    pickle.dump(data_diz, f)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../input/data-mels/DATA_Mel_spectrograms_small.pkl', 'rb') as f:\n    DATA = pickle.load(f) \n","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:37:19.027741Z","iopub.execute_input":"2022-05-21T09:37:19.028908Z","iopub.status.idle":"2022-05-21T09:37:34.922275Z","shell.execute_reply.started":"2022-05-21T09:37:19.028861Z","shell.execute_reply":"2022-05-21T09:37:34.921412Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def prepare_datasets(inputs, targets, split_size):\n      \n    #scale the data\n    mean = inputs.mean(axis=(1, 2), keepdims=True)\n    std = inputs.std(axis=(1, 2), keepdims=True)\n    inputs = (inputs-mean)/std\n    \n    # Creating a validation set and a test set.\n    inputs_train, inputs_val, targets_train, targets_val = train_test_split(inputs, targets, test_size=split_size)\n    inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs_train, targets_train, \n                                                                              test_size=split_size)\n    \n    return inputs_train, inputs_val, inputs_test, targets_train, targets_val, targets_test\n\n\ndef design_model_1(input_shape, targets):\n    \n    base_model = tf.keras.applications.densenet.DenseNet121(input_shape = input_shape, \n                                                            include_top = False, \n                                                            weights = \"imagenet\")\n    base_model.trainable = False\n\n    # Let's design the model architecture.\n    model = tf.keras.models.Sequential([\n        base_model,\n        \n        tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.3), \n        \n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(64, activation='relu'), \n        tf.keras.layers.Dense(len(np.unique(targets)), activation='softmax')\n    ])\n\n    return model\n\ndef make_prediction(model, X, y, idx):\n    \n    genre_dict = {\n        0 : 'jazz',\n        1 : 'rock',\n        2 : 'hiphop',\n        3 : \"metal\",\n        4 : \"pop\",\n        5 : \"disco\",\n        6 : \"blues\",\n        7 : \"classical\",\n        8 : \"country\",\n        9 : \"reggae\",\n        }\n        \n    predictions = model.predict(X)\n    genre = np.argmax(predictions[idx])","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:37:34.924129Z","iopub.execute_input":"2022-05-21T09:37:34.924424Z","iopub.status.idle":"2022-05-21T09:37:34.937521Z","shell.execute_reply.started":"2022-05-21T09:37:34.924387Z","shell.execute_reply":"2022-05-21T09:37:34.935831Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X = np.array(DATA['Mel_spectrograms'])\ny = np.array(DATA['label'])\ny_encoded = pd.factorize(y.reshape(X.shape[0],))[0]\ny_encoded = y_encoded.reshape(X.shape[0],1)\ninputs_train, inputs_val, inputs_test, targets_train, targets_val, targets_test = prepare_datasets(X, y_encoded, 0.1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:37:34.939306Z","iopub.execute_input":"2022-05-21T09:37:34.939726Z","iopub.status.idle":"2022-05-21T09:37:55.563583Z","shell.execute_reply.started":"2022-05-21T09:37:34.939687Z","shell.execute_reply":"2022-05-21T09:37:55.562690Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    \n\n    model = design_model_1(inputs_train.shape[1:], y)\n\n    # Selection of the optimizer, loss type and metrics for performance evaluation.\n    model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.0001),\n                     loss='sparse_categorical_crossentropy',\n                     metrics = ['acc']\n                     )\n\n    model.summary()\n\n    # Training the model.\n    history = model.fit(inputs_train, targets_train,\n                        validation_data=(inputs_val, targets_val),\n                        epochs=20,\n                        batch_size=32\n                        )\n\n    # Testing the model on never seen before data.\n    make_prediction(model, inputs_test, targets_test, 24)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:17:32.093043Z","iopub.execute_input":"2022-05-21T09:17:32.094146Z","iopub.status.idle":"2022-05-21T09:19:46.553623Z","shell.execute_reply.started":"2022-05-21T09:17:32.094104Z","shell.execute_reply":"2022-05-21T09:19:46.552761Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndensenet121 (Functional)     (None, 4, 46, 1024)       7037504   \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 2, 23, 1024)       0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 2, 23, 1024)       4096      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 2, 23, 1024)       0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 47104)             0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                3014720   \n_________________________________________________________________\ndense_3 (Dense)              (None, 10)                650       \n=================================================================\nTotal params: 10,056,970\nTrainable params: 3,017,418\nNon-trainable params: 7,039,552\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"2022-05-21 09:17:35.731406: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1863936000 exceeds 10% of free system memory.\n2022-05-21 09:17:37.630211: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1863936000 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n26/26 [==============================] - 13s 311ms/step - loss: 1.4511 - acc: 0.5192 - val_loss: 1.8242 - val_acc: 0.4900\nEpoch 2/20\n26/26 [==============================] - 6s 246ms/step - loss: 0.3879 - acc: 0.8912 - val_loss: 1.2732 - val_acc: 0.5600\nEpoch 3/20\n26/26 [==============================] - 6s 244ms/step - loss: 0.1469 - acc: 0.9654 - val_loss: 1.0089 - val_acc: 0.6300\nEpoch 4/20\n26/26 [==============================] - 6s 217ms/step - loss: 0.0590 - acc: 0.9963 - val_loss: 0.8767 - val_acc: 0.7000\nEpoch 5/20\n26/26 [==============================] - 6s 221ms/step - loss: 0.0352 - acc: 0.9988 - val_loss: 0.7682 - val_acc: 0.7600\nEpoch 6/20\n26/26 [==============================] - 6s 217ms/step - loss: 0.0255 - acc: 0.9975 - val_loss: 0.7400 - val_acc: 0.7700\nEpoch 7/20\n26/26 [==============================] - 6s 220ms/step - loss: 0.0208 - acc: 0.9975 - val_loss: 0.7154 - val_acc: 0.7500\nEpoch 8/20\n26/26 [==============================] - 6s 221ms/step - loss: 0.0177 - acc: 0.9988 - val_loss: 0.7120 - val_acc: 0.7600\nEpoch 9/20\n26/26 [==============================] - 6s 244ms/step - loss: 0.0189 - acc: 0.9988 - val_loss: 0.6494 - val_acc: 0.8000\nEpoch 10/20\n26/26 [==============================] - 6s 215ms/step - loss: 0.0122 - acc: 0.9988 - val_loss: 0.7194 - val_acc: 0.7500\nEpoch 11/20\n26/26 [==============================] - 6s 217ms/step - loss: 0.0139 - acc: 0.9988 - val_loss: 0.6518 - val_acc: 0.8100\nEpoch 12/20\n26/26 [==============================] - 6s 241ms/step - loss: 0.0099 - acc: 0.9988 - val_loss: 0.6689 - val_acc: 0.8200\nEpoch 13/20\n26/26 [==============================] - 6s 221ms/step - loss: 0.0150 - acc: 0.9988 - val_loss: 0.6752 - val_acc: 0.8100\nEpoch 14/20\n26/26 [==============================] - 6s 243ms/step - loss: 0.0167 - acc: 0.9988 - val_loss: 0.6908 - val_acc: 0.8100\nEpoch 15/20\n26/26 [==============================] - 6s 217ms/step - loss: 0.0228 - acc: 0.9975 - val_loss: 0.6923 - val_acc: 0.7800\nEpoch 16/20\n26/26 [==============================] - 6s 219ms/step - loss: 0.0076 - acc: 0.9988 - val_loss: 0.6758 - val_acc: 0.8100\nEpoch 17/20\n26/26 [==============================] - 6s 217ms/step - loss: 0.0086 - acc: 0.9988 - val_loss: 0.6536 - val_acc: 0.8300\nEpoch 18/20\n26/26 [==============================] - 6s 245ms/step - loss: 0.0089 - acc: 0.9988 - val_loss: 0.6661 - val_acc: 0.8200\nEpoch 19/20\n26/26 [==============================] - 6s 223ms/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.6951 - val_acc: 0.8100\nEpoch 20/20\n26/26 [==============================] - 6s 220ms/step - loss: 0.0062 - acc: 0.9988 - val_loss: 0.6793 - val_acc: 0.8300\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef design_model_1(input_shape, targets):\n    \n    base_model = tf.keras.applications.densenet.DenseNet121(input_shape = input_shape, \n                                                            include_top = False, \n                                                            weights = \"imagenet\")\n    base_model.trainable = False\n\n    # Let's design the model architecture.\n    model = tf.keras.models.Sequential([\n        base_model,\n        \n        tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.3), \n        \n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(64, activation='relu'), \n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(len(np.unique(targets)), activation='softmax')\n    ])\n\n    return model\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:46:15.907385Z","iopub.execute_input":"2022-05-21T09:46:15.909208Z","iopub.status.idle":"2022-05-21T09:46:15.916882Z","shell.execute_reply.started":"2022-05-21T09:46:15.909156Z","shell.execute_reply":"2022-05-21T09:46:15.915951Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    \n\n    model = design_model_1(inputs_train.shape[1:], y)\n\n    # Selection of the optimizer, loss type and metrics for performance evaluation.\n    model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.0001),\n                     loss='sparse_categorical_crossentropy',\n                     metrics = ['acc']\n                     )\n\n    model.summary()\n\n    # Training the model.\n    history = model.fit(inputs_train, targets_train,\n                        validation_data=(inputs_val, targets_val),\n                        epochs=20,\n                        batch_size=32\n                        )\n\n    # Testing the model on never seen before data.\n    make_prediction(model, inputs_test, targets_test, 24)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T09:46:15.919275Z","iopub.execute_input":"2022-05-21T09:46:15.919794Z","iopub.status.idle":"2022-05-21T09:48:53.431292Z","shell.execute_reply.started":"2022-05-21T09:46:15.919753Z","shell.execute_reply":"2022-05-21T09:48:53.430410Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndensenet121 (Functional)     (None, 4, 46, 1024)       7037504   \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 2, 23, 1024)       0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 2, 23, 1024)       4096      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 2, 23, 1024)       0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 47104)             0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                3014720   \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 64)                0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 64)                256       \n_________________________________________________________________\ndense_3 (Dense)              (None, 10)                650       \n=================================================================\nTotal params: 10,057,226\nTrainable params: 3,017,546\nNon-trainable params: 7,039,680\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"2022-05-21 09:46:19.539311: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1863936000 exceeds 10% of free system memory.\n2022-05-21 09:46:21.435616: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1863936000 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n26/26 [==============================] - 15s 358ms/step - loss: 1.7519 - acc: 0.4265 - val_loss: 1.7018 - val_acc: 0.5600\nEpoch 2/20\n26/26 [==============================] - 6s 215ms/step - loss: 0.9100 - acc: 0.7206 - val_loss: 1.3693 - val_acc: 0.6200\nEpoch 3/20\n26/26 [==============================] - 6s 219ms/step - loss: 0.6375 - acc: 0.8146 - val_loss: 1.0660 - val_acc: 0.6700\nEpoch 4/20\n26/26 [==============================] - 6s 215ms/step - loss: 0.4425 - acc: 0.9048 - val_loss: 0.9658 - val_acc: 0.7300\nEpoch 5/20\n26/26 [==============================] - 6s 218ms/step - loss: 0.3580 - acc: 0.9431 - val_loss: 0.9011 - val_acc: 0.7400\nEpoch 6/20\n26/26 [==============================] - 6s 220ms/step - loss: 0.2909 - acc: 0.9530 - val_loss: 0.8535 - val_acc: 0.7700\nEpoch 7/20\n26/26 [==============================] - 6s 216ms/step - loss: 0.2375 - acc: 0.9778 - val_loss: 0.7989 - val_acc: 0.7700\nEpoch 8/20\n26/26 [==============================] - 6s 215ms/step - loss: 0.2061 - acc: 0.9827 - val_loss: 0.7986 - val_acc: 0.7700\nEpoch 9/20\n26/26 [==============================] - 6s 218ms/step - loss: 0.1876 - acc: 0.9889 - val_loss: 0.7793 - val_acc: 0.7700\nEpoch 10/20\n26/26 [==============================] - 6s 214ms/step - loss: 0.1607 - acc: 0.9913 - val_loss: 0.7322 - val_acc: 0.7900\nEpoch 11/20\n26/26 [==============================] - 6s 218ms/step - loss: 0.1589 - acc: 0.9864 - val_loss: 0.7221 - val_acc: 0.8000\nEpoch 12/20\n26/26 [==============================] - 6s 221ms/step - loss: 0.1423 - acc: 0.9963 - val_loss: 0.7175 - val_acc: 0.7900\nEpoch 13/20\n26/26 [==============================] - 6s 218ms/step - loss: 0.1145 - acc: 0.9975 - val_loss: 0.6882 - val_acc: 0.8000\nEpoch 14/20\n26/26 [==============================] - 6s 215ms/step - loss: 0.1151 - acc: 0.9938 - val_loss: 0.6932 - val_acc: 0.8300\nEpoch 15/20\n26/26 [==============================] - 6s 216ms/step - loss: 0.1199 - acc: 0.9926 - val_loss: 0.6831 - val_acc: 0.8200\nEpoch 16/20\n26/26 [==============================] - 6s 240ms/step - loss: 0.1027 - acc: 0.9988 - val_loss: 0.6620 - val_acc: 0.8200\nEpoch 17/20\n26/26 [==============================] - 6s 223ms/step - loss: 0.0926 - acc: 0.9938 - val_loss: 0.6070 - val_acc: 0.8400\nEpoch 18/20\n26/26 [==============================] - 6s 214ms/step - loss: 0.0933 - acc: 0.9951 - val_loss: 0.6281 - val_acc: 0.8200\nEpoch 19/20\n26/26 [==============================] - 6s 219ms/step - loss: 0.0836 - acc: 0.9975 - val_loss: 0.6184 - val_acc: 0.8100\nEpoch 20/20\n26/26 [==============================] - 6s 215ms/step - loss: 0.0831 - acc: 0.9951 - val_loss: 0.5975 - val_acc: 0.8200\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}